{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-08T07:55:29.124135Z",
     "start_time": "2024-08-08T07:55:14.972785Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zeev\\anaconda3\\envs\\projtry\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\zeev\\anaconda3\\envs\\projtry\\Lib\\site-packages\\transformers\\models\\paligemma\\configuration_paligemma.py:137: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.44, Please use `text_config.vocab_size` instead.\n",
      "  warnings.warn(\n",
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.47s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
    "from PIL import Image\n",
    "import torch\n",
    "google_token = '<ADD YOUR TOKEN HERE>'\n",
    "model_id = \"google/paligemma-3b-mix-224\"\n",
    "device = \"cuda:0\"\n",
    "dtype = torch.bfloat16\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=device,\n",
    "    revision=\"bfloat16\",\n",
    "    token=google_token\n",
    ").eval()\n",
    "processor = AutoProcessor.from_pretrained(model_id,\n",
    "    token=google_token)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 1\n",
      "Done with 10\n",
      "Done with 106\n",
      "Done with 11\n",
      "Done with 111\n",
      "Done with 113\n",
      "Done with 116\n",
      "Done with 117\n",
      "Done with 118\n",
      "Done with 119\n",
      "Done with 12\n",
      "Done with 124\n",
      "Done with 127\n",
      "Done with 13\n",
      "Done with 131\n",
      "Done with 132\n",
      "Done with 133\n",
      "Done with 134\n",
      "Done with 136\n",
      "Done with 14\n",
      "Done with 140\n",
      "Done with 141\n",
      "Done with 145\n",
      "Done with 149\n",
      "Done with 15\n",
      "Done with 150\n",
      "Done with 153\n",
      "Done with 156\n",
      "Done with 158\n",
      "Done with 159\n",
      "Done with 16\n",
      "Done with 162\n",
      "Done with 164\n",
      "Done with 167\n",
      "Done with 168\n",
      "Done with 17\n",
      "Done with 172\n",
      "Done with 174\n",
      "Done with 177\n",
      "Done with 178\n",
      "Done with 179\n",
      "Done with 18\n",
      "Done with 181\n",
      "Done with 182\n",
      "Done with 184\n",
      "Done with 187\n",
      "Done with 188\n",
      "Done with 189\n",
      "Done with 19\n",
      "Done with 192\n",
      "Done with 193\n",
      "Done with 194\n",
      "Done with 195\n",
      "Done with 196\n",
      "Done with 199\n",
      "Done with 2\n",
      "Done with 20\n",
      "Done with 200\n",
      "Done with 204\n",
      "Done with 205\n",
      "Done with 208\n",
      "Done with 21\n",
      "Done with 212\n",
      "Done with 213\n",
      "Done with 214\n",
      "Done with 217\n",
      "Done with 218\n",
      "Done with 219\n",
      "Done with 22\n",
      "Done with 223\n",
      "Done with 227\n",
      "Done with 228\n",
      "Done with 229\n",
      "Done with 23\n",
      "Done with 232\n",
      "Done with 233\n",
      "Done with 234\n",
      "Done with 24\n",
      "Done with 241\n",
      "Done with 243\n",
      "Done with 244\n",
      "Done with 248\n",
      "Done with 249\n",
      "Done with 25\n",
      "Done with 251\n",
      "Done with 256\n",
      "Done with 257\n",
      "Done with 258\n",
      "Done with 26\n",
      "Done with 260\n",
      "Done with 263\n",
      "Done with 265\n",
      "Done with 267\n",
      "Done with 268\n",
      "Done with 27\n",
      "Done with 270\n",
      "Done with 271\n",
      "Done with 272\n",
      "Done with 273\n",
      "Done with 274\n",
      "Done with 275\n",
      "Done with 276\n",
      "Done with 277\n",
      "Done with 278\n",
      "Done with 279\n",
      "Done with 28\n",
      "Done with 280\n",
      "Done with 281\n",
      "Done with 282\n",
      "Done with 283\n",
      "Done with 284\n",
      "Done with 285\n",
      "Done with 29\n",
      "Done with 290\n",
      "Done with 291\n",
      "Done with 292\n",
      "Done with 293\n",
      "Done with 294\n",
      "Done with 296\n",
      "Done with 297\n",
      "Done with 298\n",
      "Done with 299\n",
      "Done with 3\n",
      "Done with 30\n",
      "Done with 300\n",
      "Done with 307\n",
      "Done with 308\n",
      "Done with 309\n",
      "Done with 31\n",
      "Done with 310\n",
      "Done with 311\n",
      "Done with 312\n",
      "Done with 313\n",
      "Done with 314\n",
      "Done with 315\n",
      "Done with 316\n",
      "Done with 317\n",
      "Done with 318\n",
      "Done with 319\n",
      "Done with 32\n",
      "Done with 320\n",
      "Done with 321\n",
      "Done with 322\n",
      "Done with 323\n",
      "Done with 324\n",
      "Done with 325\n",
      "Done with 326\n",
      "Done with 327\n",
      "Done with 328\n",
      "Done with 329\n",
      "Done with 33\n",
      "Done with 330\n",
      "Done with 331\n",
      "Done with 332\n",
      "Done with 333\n",
      "Done with 334\n",
      "Done with 335\n",
      "Done with 336\n",
      "Done with 337\n",
      "Done with 338\n",
      "Done with 339\n",
      "Done with 34\n",
      "Done with 340\n",
      "Done with 341\n",
      "Done with 342\n",
      "Done with 343\n",
      "Done with 344\n",
      "Done with 345\n",
      "Done with 346\n",
      "Done with 347\n",
      "Done with 348\n",
      "Done with 349\n",
      "Done with 35\n",
      "Done with 350\n",
      "Done with 351\n",
      "Done with 352\n",
      "Done with 353\n",
      "Done with 354\n",
      "Done with 355\n",
      "Done with 356\n",
      "Done with 357\n",
      "Done with 358\n",
      "Done with 36\n",
      "Done with 37\n",
      "Done with 38\n",
      "Done with 39\n",
      "Done with 4\n",
      "Done with 40\n",
      "Done with 41\n",
      "Done with 42\n",
      "Done with 44\n",
      "Done with 45\n",
      "Done with 46\n",
      "Done with 47\n",
      "Done with 48\n",
      "Done with 49\n",
      "Done with 5\n",
      "Done with 50\n",
      "Done with 51\n",
      "Done with 52\n",
      "Done with 53\n",
      "Done with 54\n",
      "Done with 55\n",
      "Done with 56\n",
      "Done with 57\n",
      "Done with 58\n",
      "Done with 59\n",
      "Done with 6\n",
      "Done with 60\n",
      "Done with 63\n",
      "Done with 64\n",
      "Done with 66\n",
      "Done with 67\n",
      "Done with 68\n",
      "Done with 69\n",
      "Done with 7\n",
      "Done with 70\n",
      "Done with 71\n",
      "Done with 72\n",
      "Done with 73\n",
      "Done with 76\n",
      "Done with 78\n",
      "Done with 79\n",
      "Done with 8\n",
      "Done with 83\n",
      "Done with 84\n",
      "Done with 85\n",
      "Done with 86\n",
      "Done with 87\n",
      "Done with 88\n",
      "Done with 9\n",
      "Done with 90\n",
      "Done with 92\n",
      "Done with 93\n",
      "Done with 99\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "def run_model(image1, image2):\n",
    "    prompt = \"you are presented with 3 images. given the left most image (context) which one of the other two optional scenes is more plausible? answer only 'middle' or 'right'\"\n",
    "    model_inputs1 = processor(text=prompt, images=image1, return_tensors=\"pt\").to(model.device)\n",
    "    model_inputs2 = processor(text=prompt, images=image2, return_tensors=\"pt\").to(model.device)\n",
    "    input_len1 = model_inputs1[\"input_ids\"].shape[-1]\n",
    "    input_len2 = model_inputs2[\"input_ids\"].shape[-1]\n",
    "    with torch.inference_mode():\n",
    "        generation = model.generate(**model_inputs1, max_new_tokens=100, do_sample=False)\n",
    "        generation = generation[0][input_len1:]\n",
    "        res1 = processor.decode(generation, skip_special_tokens=True)\n",
    "        generation = model.generate(**model_inputs2, max_new_tokens=100, do_sample=False)\n",
    "        generation = generation[0][input_len2:]\n",
    "        res2 = processor.decode(generation, skip_special_tokens=True)\n",
    "    return res1, res2\n",
    "df = pd.DataFrame(columns=['folder', 'dataset', 'style', 'result', 'result_reversed'])\n",
    "dataset = \"combined_dataset\"\n",
    "for folder in os.listdir(dataset):\n",
    "    for inner_dataset in os.listdir(os.path.join(dataset, folder)):\n",
    "        for style in os.listdir(os.path.join(dataset, folder, inner_dataset)):\n",
    "            image1 = Image.open(os.path.join(dataset, folder, inner_dataset, style, 'combined_image.png')).convert('RGB')\n",
    "            image2 = Image.open(os.path.join(dataset, folder, inner_dataset, style, 'combined_image_reversed.png')).convert('RGB')\n",
    "            res1, res2 = run_model(image1, image2)\n",
    "            new_rows = pd.DataFrame([{'folder': folder, 'dataset': inner_dataset, 'style': style, 'result': res1, 'result_reversed': res2}])\n",
    "            df = pd.concat([df, new_rows], ignore_index=True)\n",
    "            df.to_csv('google_paligemma-3b-mix-224_result_all.csv', index=False)\n",
    "    print('Done with', folder)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T08:19:59.103618Z",
     "start_time": "2024-08-08T08:15:33.088321Z"
    }
   },
   "id": "3ce374e7a69ed79",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zeev\\anaconda3\\envs\\projtry\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.92s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "MiniCPMV(\n  (llm): LlamaForCausalLM(\n    (model): LlamaModel(\n      (embed_tokens): Embedding(128256, 4096)\n      (layers): ModuleList(\n        (0-31): 32 x LlamaDecoderLayer(\n          (self_attn): LlamaSdpaAttention(\n            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n            (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n            (rotary_emb): LlamaRotaryEmbedding()\n          )\n          (mlp): LlamaMLP(\n            (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n            (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n            (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n            (act_fn): SiLU()\n          )\n          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n        )\n      )\n      (norm): LlamaRMSNorm((4096,), eps=1e-05)\n      (rotary_emb): LlamaRotaryEmbedding()\n    )\n    (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n  )\n  (vpm): Idefics2VisionTransformer(\n    (embeddings): Idefics2VisionEmbeddings(\n      (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n      (position_embedding): Embedding(4900, 1152)\n    )\n    (encoder): Idefics2Encoder(\n      (layers): ModuleList(\n        (0-26): 27 x Idefics2EncoderLayer(\n          (self_attn): Idefics2VisionAttention(\n            (k_proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n            (v_proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n            (q_proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n            (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n          )\n          (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n          (mlp): Idefics2VisionMLP(\n            (activation_fn): PytorchGELUTanh()\n            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n          )\n          (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n        )\n      )\n    )\n    (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n  )\n  (resampler): Resampler(\n    (kv_proj): Linear(in_features=1152, out_features=4096, bias=False)\n    (attn): MultiheadAttention(\n      (out_proj): NonDynamicallyQuantizableLinear(in_features=4096, out_features=4096, bias=True)\n    )\n    (ln_q): LayerNorm((4096,), eps=1e-06, elementwise_affine=True)\n    (ln_kv): LayerNorm((4096,), eps=1e-06, elementwise_affine=True)\n    (ln_post): LayerNorm((4096,), eps=1e-06, elementwise_affine=True)\n  )\n)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model = AutoModel.from_pretrained('openbmb/MiniCPM-Llama3-V-2_5-int4', trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-Llama3-V-2_5-int4', trust_remote_code=True)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T08:30:08.109164Z",
     "start_time": "2024-08-08T08:29:54.395532Z"
    }
   },
   "id": "e677cd56362ff109",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def run_model(image1, image2, image3):\n",
    "    question = 'describe in a sentence each image. based on the context which one of the other two images is more plausible? answer \"first\" or \"second\"'\n",
    "    msgs1 = [{'role': 'user', 'content': \n",
    "        ['this is the context image:',image1, 'this is the first plausible image:',image2, 'this is the second plausible image:',image3, question]\n",
    "             }]\n",
    "    msgs2 = [{'role': 'user', 'content': \n",
    "        ['this is the context image:',image1, 'this is the first plausible image:',image3, 'this is the second plausible image:',image2, question]\n",
    "             }]\n",
    "    \n",
    "    res1 = model.chat(\n",
    "        image=None,\n",
    "        msgs=msgs1,\n",
    "        tokenizer=tokenizer,\n",
    "        sampling=True, # if sampling=False, beam_search will be used by default\n",
    "        temperature=0.7,\n",
    "        # system_prompt='' # pass system_prompt if needed\n",
    "    )\n",
    "    res2 = model.chat(\n",
    "        image=None,\n",
    "        msgs=msgs2,\n",
    "        tokenizer=tokenizer,\n",
    "        sampling=True, # if sampling=False, beam_search will be used by default\n",
    "        temperature=0.7,\n",
    "        # system_prompt='' # pass system_prompt if needed\n",
    "    )\n",
    "    return res1, res2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T08:30:38.674483Z",
     "start_time": "2024-08-08T08:30:38.670554Z"
    }
   },
   "id": "d54071fcc69be88b",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 1\n",
      "Done with 10\n",
      "Done with 106\n",
      "Done with 11\n",
      "Done with 111\n",
      "Done with 113\n",
      "Done with 116\n",
      "Done with 117\n",
      "Done with 118\n",
      "Done with 119\n",
      "Done with 12\n",
      "Done with 124\n",
      "Done with 127\n",
      "Done with 13\n",
      "Done with 131\n",
      "Done with 132\n",
      "Done with 133\n",
      "Done with 134\n",
      "Done with 136\n",
      "Done with 14\n",
      "Done with 140\n",
      "Done with 141\n",
      "Done with 145\n",
      "Done with 149\n",
      "Done with 15\n",
      "Done with 150\n",
      "Done with 153\n",
      "Done with 156\n",
      "Done with 158\n",
      "Done with 159\n",
      "Done with 16\n",
      "Done with 162\n",
      "Done with 164\n",
      "Done with 167\n",
      "Done with 168\n",
      "Done with 17\n",
      "Done with 172\n",
      "Done with 174\n",
      "Done with 177\n",
      "Done with 178\n",
      "Done with 179\n",
      "Done with 18\n",
      "Done with 181\n",
      "Done with 182\n",
      "Done with 184\n",
      "Done with 187\n",
      "Done with 188\n",
      "Done with 189\n",
      "Done with 19\n",
      "Done with 192\n",
      "Done with 193\n",
      "Done with 194\n",
      "Done with 195\n",
      "Done with 196\n",
      "Done with 199\n",
      "Done with 2\n",
      "Done with 20\n",
      "Done with 200\n",
      "Done with 204\n",
      "Done with 205\n",
      "Done with 208\n",
      "Done with 21\n",
      "Done with 212\n",
      "Done with 213\n",
      "Done with 214\n",
      "Done with 217\n",
      "Done with 218\n",
      "Done with 219\n",
      "Done with 22\n",
      "Done with 223\n",
      "Done with 227\n",
      "Done with 228\n",
      "Done with 229\n",
      "Done with 23\n",
      "Done with 232\n",
      "Done with 233\n",
      "Done with 234\n",
      "Done with 24\n",
      "Done with 241\n",
      "Done with 243\n",
      "Done with 244\n",
      "Done with 248\n",
      "Done with 249\n",
      "Done with 25\n",
      "Done with 251\n",
      "Done with 256\n",
      "Done with 257\n",
      "Done with 258\n",
      "Done with 26\n",
      "Done with 260\n",
      "Done with 263\n",
      "Done with 265\n",
      "Done with 267\n",
      "Done with 268\n",
      "Done with 27\n",
      "Done with 270\n",
      "Done with 271\n",
      "Done with 272\n",
      "Done with 273\n",
      "Done with 274\n",
      "Done with 275\n",
      "Done with 276\n",
      "Done with 277\n",
      "Done with 278\n",
      "Done with 279\n",
      "Done with 28\n",
      "Done with 280\n",
      "Done with 281\n",
      "Done with 282\n",
      "Done with 283\n",
      "Done with 284\n",
      "Done with 285\n",
      "Done with 29\n",
      "Done with 290\n",
      "Done with 291\n",
      "Done with 292\n",
      "Done with 293\n",
      "Done with 294\n",
      "Done with 296\n",
      "Done with 297\n",
      "Done with 298\n",
      "Done with 299\n",
      "Done with 3\n",
      "Done with 30\n",
      "Done with 300\n",
      "Done with 307\n",
      "Done with 308\n",
      "Done with 309\n",
      "Done with 31\n",
      "Done with 310\n",
      "Done with 311\n",
      "Done with 312\n",
      "Done with 313\n",
      "Done with 314\n",
      "Done with 315\n",
      "Done with 316\n",
      "Done with 317\n",
      "Done with 318\n",
      "Done with 319\n",
      "Done with 32\n",
      "Done with 320\n",
      "Done with 321\n",
      "Done with 322\n",
      "Done with 323\n",
      "Done with 324\n",
      "Done with 325\n",
      "Done with 326\n",
      "Done with 327\n",
      "Done with 328\n",
      "Done with 329\n",
      "Done with 33\n",
      "Done with 330\n",
      "Done with 331\n",
      "Done with 332\n",
      "Done with 333\n",
      "Done with 334\n",
      "Done with 335\n",
      "Done with 336\n",
      "Done with 337\n",
      "Done with 338\n",
      "Done with 339\n",
      "Done with 34\n",
      "Done with 340\n",
      "Done with 341\n",
      "Done with 342\n",
      "Done with 343\n",
      "Done with 344\n",
      "Done with 345\n",
      "Done with 346\n",
      "Done with 347\n",
      "Done with 348\n",
      "Done with 349\n",
      "Done with 35\n",
      "Done with 350\n",
      "Done with 351\n",
      "Done with 352\n",
      "Done with 353\n",
      "Done with 354\n",
      "Done with 355\n",
      "Done with 356\n",
      "Done with 357\n",
      "Done with 358\n",
      "Done with 36\n",
      "Done with 37\n",
      "Done with 38\n",
      "Done with 39\n",
      "Done with 4\n",
      "Done with 40\n",
      "Done with 41\n",
      "Done with 42\n",
      "Done with 44\n",
      "Done with 45\n",
      "Done with 46\n",
      "Done with 47\n",
      "Done with 48\n",
      "Done with 49\n",
      "Done with 5\n",
      "Done with 50\n",
      "Done with 51\n",
      "Done with 52\n",
      "Done with 53\n",
      "Done with 54\n",
      "Done with 55\n",
      "Done with 56\n",
      "Done with 57\n",
      "Done with 58\n",
      "Done with 59\n",
      "Done with 6\n",
      "Done with 60\n",
      "Done with 63\n",
      "Done with 64\n",
      "Done with 66\n",
      "Done with 67\n",
      "Done with 68\n",
      "Done with 69\n",
      "Done with 7\n",
      "Done with 70\n",
      "Done with 71\n",
      "Done with 72\n",
      "Done with 73\n",
      "Done with 76\n",
      "Done with 78\n",
      "Done with 79\n",
      "Done with 8\n",
      "Done with 83\n",
      "Done with 84\n",
      "Done with 85\n",
      "Done with 86\n",
      "Done with 87\n",
      "Done with 88\n",
      "Done with 9\n",
      "Done with 90\n",
      "Done with 92\n",
      "Done with 93\n",
      "Done with 99\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df = pd.DataFrame(columns=['folder', 'dataset', 'style', 'result', 'result_reversed'])\n",
    "dataset = \"combined_dataset\"\n",
    "for folder in os.listdir(dataset):\n",
    "    for inner_dataset in os.listdir(os.path.join(dataset, folder)):\n",
    "        for style in os.listdir(os.path.join(dataset, folder, inner_dataset)):\n",
    "            for file in os.listdir(os.path.join(dataset, folder, inner_dataset, style)):\n",
    "                if 'premise' in file and '_' not in file:\n",
    "                    image1 = Image.open(os.path.join(dataset, folder, inner_dataset, style, file)).convert('RGB').resize((512,512))\n",
    "                if 'hypothesis1' in file and '_' not in file:\n",
    "                    image2 = Image.open(os.path.join(dataset, folder, inner_dataset, style, file)).convert('RGB').resize((512,512))\n",
    "                if 'hypothesis2' in file and '_' not in file:\n",
    "                    image3 = Image.open(os.path.join(dataset, folder, inner_dataset, style, file)).convert('RGB').resize((512,512))\n",
    "            res1, res2 = run_model(image1, image2, image3)\n",
    "            new_rows = pd.DataFrame([{'folder': folder, 'dataset': inner_dataset, 'style': style, 'result': res1, 'result_reversed': res2}])\n",
    "            df = pd.concat([df, new_rows], ignore_index=True)\n",
    "            df.to_csv('openbmb_MiniCPM-Llama3-V-2_5-int4_result_all.csv', index=False)\n",
    "            image1=None\n",
    "            image2=None\n",
    "            image3=None\n",
    "    print('Done with', folder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T10:32:16.412367Z",
     "start_time": "2024-08-08T08:32:25.852777Z"
    }
   },
   "id": "3dc329c85e4b92ab",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zeev\\anaconda3\\envs\\projtry\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:28<00:00,  4.10s/it]\n",
      "Chat templates should be in a 'chat_template.json' file but found key='chat_template' in the processor's config. Make sure to move your template to its own file.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "from transformers.image_utils import load_image\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"HuggingFaceM4/idefics2-8b\",\n",
    "    torch_dtype=torch.float16,    \n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceM4/idefics2-8b\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T11:49:08.744155Z",
     "start_time": "2024-08-08T11:48:33.976488Z"
    }
   },
   "id": "b3e94ad2b34ff41",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"This image is the context image:\"},\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"This image is scenario 1:\"},\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"This image is scenario 2:\"},\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Based on the context image, which scenario is more plausible?\"},\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "def run_model(image1, image2, image3):\n",
    "    prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(text=prompt, images=[image1, image2,image3], return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "    \n",
    "    # Generate\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=100)\n",
    "    generated_texts = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    return generated_texts[0].split('Assistant: ')[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T11:49:08.749082Z",
     "start_time": "2024-08-08T11:49:08.745163Z"
    }
   },
   "id": "b85431c76359f4c",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 353 VLM image dataset anime\n",
      "Starting with 353 VLM image dataset paper cut\n",
      "Starting with 353 VLM image dataset photorialistic\n",
      "Starting with 353 VLM image dataset sketched\n",
      "Done with 353\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df = pd.DataFrame(columns=['folder', 'dataset', 'style', 'result', 'result_reversed'])\n",
    "dataset = \"combined_dataset\"\n",
    "for folder in os.listdir(dataset):\n",
    "    for inner_dataset in os.listdir(os.path.join(dataset, folder)):\n",
    "        for style in os.listdir(os.path.join(dataset, folder, inner_dataset)): \n",
    "            print('Starting with', folder, inner_dataset, style)\n",
    "            for file in os.listdir(os.path.join(dataset, folder, inner_dataset, style)):\n",
    "                if 'premise' in file and '_' not in file:\n",
    "                    image1 = Image.open(os.path.join(dataset, folder, inner_dataset, style, file)).convert('RGB').resize((512,512))\n",
    "                if 'hypothesis1' in file and '_' not in file:\n",
    "                    image2 = Image.open(os.path.join(dataset, folder, inner_dataset, style, file)).convert('RGB').resize((512,512))\n",
    "                if 'hypothesis2' in file and '_' not in file:\n",
    "                    image3 = Image.open(os.path.join(dataset, folder, inner_dataset, style, file)).convert('RGB').resize((512,512))\n",
    "            res1 = run_model(image1, image2, image3)\n",
    "            res2 = run_model(image1, image3, image2)\n",
    "            new_rows = pd.DataFrame([{'folder': folder, 'dataset': inner_dataset, 'style': style, 'result': res1, 'result_reversed': res2}])\n",
    "            df = pd.concat([df, new_rows], ignore_index=True)\n",
    "            df.to_csv('HuggingFaceM4_idefics2-8b_result_356.csv', index=False)\n",
    "            image1=None\n",
    "            image2=None\n",
    "            image3=None\n",
    "    print('Done with', folder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T14:47:50.529148Z",
     "start_time": "2024-08-08T14:46:44.773409Z"
    }
   },
   "id": "fc9e2c0c3bbb2fcd",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "csv = pd.read_csv('HuggingFaceM4_idefics2-8b_result_all.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T13:23:24.952636Z",
     "start_time": "2024-08-08T13:23:24.945400Z"
    }
   },
   "id": "fdcf9d3bcc9b8dc1",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get all folder id's from csv\n",
    "folders = set(csv['folder'].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T13:24:13.534213Z",
     "start_time": "2024-08-08T13:24:13.531527Z"
    }
   },
   "id": "dc47db2115bb0721",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# change the filders ids to string\n",
    "folders = [str(folder) for folder in folders]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T13:26:43.942002Z",
     "start_time": "2024-08-08T13:26:43.939321Z"
    }
   },
   "id": "49cc463214e3058c",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T10:26:40.169713Z",
     "start_time": "2024-12-13T10:26:40.151919Z"
    }
   },
   "id": "a87fbf31c661c9f3",
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
